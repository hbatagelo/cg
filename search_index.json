[["texturing.html", "11 Texturização", " 11 Texturização Texturização, ou mapeamento de textura, é uma técnica de síntese de imagens que consiste em mapear coordenadas de pontos de uma superfície 3D para pontos de um mapa de textura, também chamado simplesmente de textura. Em geral, uma textura é uma imagem digital armazenada como um mapa de bits. Entretanto, texturas também podem ser geradas de forma procedural através da avaliação de funções ou algoritmos. Um exemplo de textura procedural é uma textura obtida através da avaliação de um fractal ou função de geração de ruído. Os valores de uma textura podem ser utilizados para modificar as propriedades locais do material em cada ponto da superfície. Com isso, pode-se aumentar o nível de detalhes do objeto renderizado sem precisar aumentar o número de vértices da malha geométrica. A figura 11.1 mostra um exemplo de mapeamento de uma textura retangular (uma imagem bitmap) sobre uma esfera unitária que representa a Terra. A esfera é renderizada com o modelo de reflexão de Blinn-Phong e sombreamento de Phong. As cores RGB da textura são usadas neste caso para definir os valores de reflexão difusa do material (\\(\\kappa_d\\)). Uma textura que, como esta, modifica os valores de reflexão difusa, é chamada de textura difusa. Figura 11.1: Mapeamento de textura sobre uma esfera representando a Terra. No mapeamento da figura 11.1, cada ponto \\((x,y,z) \\in \\mathbb{R}^3\\) da esfera centralizada na origem e com polos alinhados com o eixo \\(y\\), corresponde a um ponto \\((u,v) \\in \\mathbb{R}^2\\) do espaço de textura. O mapeamento realizado é um mapeamento esférico, definido pelas equações \\[ \\begin{align} u&amp;=\\frac{\\textrm{arctan2}\\left(x, z\\right)}{2\\pi}+0.5,\\\\ v&amp;=\\frac{\\arcsin(y)}{\\pi}+0.5, \\end{align} \\] onde \\(\\textrm{arctan2}(x, z)\\) é a função atan2 que corresponde ao arco tangente de \\(x/z\\), mas que retorna um ângulo no intervalo \\([-\\pi, \\pi]\\) e usa os sinais dos argumentos para determinar o quadrante correto no plano \\(zx\\). O mapeamento esférico é detalhado na seção 11.1 junto com outras formas comuns de mapeamento. A operação de determinar o valor da textura em um ponto \\((u,v)\\) é chamada de amostragem de textura. No OpenGL é possível amostrar texturas nos shaders e configurar o comportamento do amostrador para produzir diferentes efeitos. A menor unidade de uma textura é comumente chamada de texel (texture element). Um texel é simplesmente um pixel do mapa da textura. Entretanto, o termo texel é usado no lugar de pixel neste contexto porque um pixel da textura (isto é, um texel) nem sempre corresponde exatamente a um pixel da tela. Durante a amostragem de textura, é comum que um texel seja mapeado para vários pixels do framebuffer, ou que muitos texels sejam mapeados para apenas um pixel. Podemos definir critérios de filtragem de textura para definir o que deve ser feito em cada caso. Os modos de filtragem de textura utilizados no OpenGL são descritos na seção 11.3. As coordenadas \\((u,v)\\) do espaço de textura são chamadas de coordenadas de textura. No OpenGL, a origem das coordenadas do espaço de textura é o canto inferior esquerdo da textura. O canto superior direito tem coordenadas \\((1,1)\\). É possível amostrar uma textura em coordenadas fora do intervalo \\([0,1]\\), mas nesse caso o comportamento será definido de acordo com o modo de “empacotamento” de textura da API. Os diferentes comportamentos possíveis no OpenGL são descritos na seção 11.2. Nosso foco será no uso de texturas 2D (GL_TEXTURE_2D). Entretanto, o OpenGL também fornece suporte a texturas 1D (GL_TEXTURE_1D) e 3D (GL_TEXTURE_3D). Uma textura 1D só possui uma coordenada \\(u\\) e é composta por uma sequência linear de texels. De forma semelhante, uma textura 3D possui coordenadas \\((u,v,w)\\) e é composta por um volume de texels. "],["texmapping.html", "11.1 Mapeamento", " 11.1 Mapeamento Nesta seção, veremos algumas das funções de mapeamento mais utilizadas para mapear coordenadas \\((x,y,z)\\) do espaço 3D para coordenadas \\((u,v)\\) do espaço 2D de um mapa de textura: o mapeamento planar, o mapeamento cilíndrico e o mapeamento esférico. Além desses, abordaremos também o mapeamento UV unwrap, também chamado de desdobramento UV, muito utilizado em programas de modelagem 3D e jogos. Para simplificar, vamos considerar nesta seção que as coordenadas de textura estão restritas ao intervalo \\([0,1]\\). Entretanto, isso não é uma limitação rígida. Coordenadas fora desse intervalo podem ser tratadas de acordo com as abordagens descritas na seção 11.2. Mapeamento planar O mapeamento planar consiste em uma projeção linear e paralela dos pontos do espaço 3D para o plano do espaço de textura 2D. Geralmente a projeção é feita na direção de algum eixo principal do espaço 3D. Por exemplo, um mapeamento planar na direção do eixo \\(x\\) pode ser definido como: \\[ \\begin{align} u&amp;=1-z,\\\\ v&amp;=y. \\end{align} \\] Considere o mapa de textura difusa mostrado na figura 11.2. Usando mapeamento planar na direção de \\(x\\), um cubo unitário de \\((0,0,0)\\) a \\((1,1,1)\\) mapeado com essa textura terá a aparência mostrada na figura 11.3. Figura 11.2: Textura difusa com padrão de teste. Figura 11.3: Mapeamento planar na direção x sobre um cubo unitário. Observe como o lado de cima e lado esquerdo do cubo repetem, respectivamente, a cor dos texels com \\(v=1\\) e \\(u=0\\) (a mudança de tom é resultado da iluminação). Isso acontece porque todos os pontos ao longo de uma reta na direção \\(x\\) são mapeados para um mesmo texel. Um mapeamento planar na direção do eixo \\(y\\) pode ser definido como: \\[ \\begin{align} u&amp;=x,\\\\ v&amp;=1-z. \\end{align} \\] A figura 11.4 mostra o resultado desse mapeamento sobre o cubo unitário. Figura 11.4: Mapeamento planar na direção y sobre um cubo unitário. Um mapeamento planar na direção do eixo \\(z\\) pode ser definido como: \\[ \\begin{align} u&amp;=x,\\\\ v&amp;=y. \\end{align} \\] A figura 11.5 mostra o resultado desse mapeamento sobre o cubo unitário. Figura 11.5: Mapeamento planar na direção z sobre um cubo unitário. Os mapeamentos planares nas direções \\(x\\), \\(y\\) e \\(z\\) podem ser combinados para formar um mapeamento triplanar. A ideia consiste em calcular três pares de coordenadas \\((u,v)\\), um para cada mapeamento planar, \\[ (u_x,v_x),\\qquad(u_y,v_y),\\qquad(u_z,v_z), \\] e então combinar o valor dos texels amostrados com essas coordenadas de acordo com algum critério. Um critério simples é calcular uma média ponderada dos texels. Os pesos da média podem ser as coordenadas \\((n_x, n_y, n_z)\\) do vetor normal normalizado, em valor absoluto. Por exemplo, se \\(T(u,v)\\) é o texel amostrado na posição \\((u,v)\\) do espaço de textura, a combinação do mapeamento triplanar pode ser calculada como \\[ T(u_x, v_x)|n_x| + T(u_y, v_y)|n_y| + T(u_z, v_z)|n_z|. \\] Na renderização do cubo unitário, o resultado será semelhante ao exibido na figura 11.6. Figura 11.6: Mapeamento triplanar sobre um cubo unitário. Mapeamento cilíndrico No mapeamento cilíndrico, a textura é mapeada de tal forma que, se o objeto renderizado é um cilindro, o resultado será equivalente a envolver a área lateral do cilindro com a textura. A figura 11.7 ilustra um exemplo de mapeamento cilíndrico mostrando a visão de frente e de trás do cilindro. Neste caso, consideramos que o cilindro é unitário, alinhado e centralizado com o eixo \\(y\\), com base em \\(y=0\\). Observe como os lados esquerdo (\\(u=0\\)) e direito (\\(u=1\\)) da textura se unem na parte de trás do cilindro. Figura 11.7: Mapeamento cilíndrico em um cilindro unitário. Seja \\(\\mathbf{p}=\\begin{bmatrix}p_x &amp; p_y &amp; p_z\\end{bmatrix}^T\\) um ponto do espaço euclidiano. O mapeamento cilíndrico para o cilindro da figura 11.7 é definido a partir do ângulo \\(\\theta\\) que \\(\\mathbf{p}\\) forma em torno do eixo \\(y\\), e a elevação \\(p_y\\) (figura 11.8): Figura 11.8: Geometria do mapeamento cilíndrico. O ângulo \\(\\theta \\in [-\\pi, \\pi]\\) é mapeado para \\(u \\in [0,1]\\). A altura \\(y\\) é mapeada diretamente para \\(v\\), isto é, \\(v=p_y\\). Observe que \\[ \\tan{\\theta}=\\frac{p_x}{p_z}. \\] Logo, \\[ \\theta=\\arctan\\left({\\frac{p_x}{p_z}}\\right). \\] O ângulo é calculado corretamente para \\(p_z&gt;0\\). Entretanto, a imagem da função arco tangente está restrita ao intervalo \\(\\left(-\\frac{\\pi}{2}, \\frac{\\pi}{2}\\right)\\). Para que \\(\\theta\\) seja um ângulo em um intervalo de 360 graus, precisamos ajustar o intervalo da função arco tangente de acordo com o sinal de \\(p_x\\) e \\(p_z\\). Como já vimos, isso pode ser obtido através da função atan2 Essa função está presente nas bibliotecas matemáticas das principais linguagens de programação. Por exemplo, na biblioteca padrão do C++, a função é implementada por std::atan2. Em GLSL, o nome da função é atan e recebe dois parâmetros (a função com um parâmetro é a função arco tangente convencional). A conversão de \\(\\theta \\in [-\\pi, \\pi]\\) para \\(u \\in [0,1]\\) é obtida com o simples mapeamento linear: \\[ u = \\frac{\\theta}{2\\pi}+0.5. \\] Logo, o mapeamento cilíndrico é definido como \\[ \\begin{align} u&amp;=\\frac{\\textrm{arctan2}\\left(p_x, p_z\\right)}{2\\pi}+0.5,\\\\ v&amp;=p_y, \\end{align} \\] Mapeamento esférico No mapeamento esférico, a textura é mapeada de tal forma que, se o objeto renderizado é uma esfera centralizada na origem, o resultado será equivalente a envolver a esfera fazendo com que \\(u\\) e \\(v\\) sejam, respectivamente, a longitude e a latitude, como em uma projeção cilíndrica equidistante usada em cartografia. Vamos considerar que os polos estão alinhados ao eixo \\(y\\). Desse modo: Os texels da linha \\(v=0\\) e \\(v=1\\) serão mapeados, respectivamente, para o polo sul e polo norte; Os texels com \\(v=0.5\\) serão mapeados para o equador da esfera, que neste caso é o plano \\(y=0\\); Os texels com \\(u=0\\) e \\(u=1\\) serão mapeados para o meridiano central no plano \\(yz\\) com \\(z&lt;0\\). A figura 11.9 mostra um exemplo de esfera texturizada com mapeamento esférico, visto de frente e de cima (polo norte). Figura 11.9: Mapeamento esférico em uma esfera unitária. Seja \\(\\mathbf{p}=\\begin{bmatrix}p_x &amp; p_y &amp; p_z\\end{bmatrix}^T\\) um ponto do espaço euclidiano. O mapeamento cilíndrico é definido a partir do ângulo \\(\\theta\\) (longitude) e \\(\\phi\\) (latitude) da esfera que contém \\(\\mathbf{p}\\), como mostra a geometria da figura 11.10. Figura 11.10: Geometria do mapeamento esférico. A coordenada \\(u\\) é calculada como no mapeamento cilíndrico: \\[ u=\\frac{\\textrm{arctan2}\\left(p_x, p_z\\right)}{2\\pi}+0.5. \\] Para determinar \\(v\\), observe, na figura 11.10, que \\[ \\begin{align} \\sin \\phi = \\frac{p_y}{|\\mathbf{p}|}.\\\\ \\end{align} \\] Logo, \\[ \\phi = \\arcsin \\left( \\frac{p_y}{|\\mathbf{p}|} \\right), \\] onde \\[ |\\mathbf{p}|=\\sqrt{x^2+y^2+z^2}. \\] A conversão de \\(\\phi \\in \\left[-\\frac{\\pi}{2}, \\frac{\\pi}{2}\\right]\\) para \\(v \\in [0,1]\\) é obtida com o mapeamento linear: \\[ v = \\frac{\\phi}{\\pi}+0.5. \\] Logo, o mapeamento esférico é definido como \\[ \\begin{align} u&amp;=\\frac{\\textrm{arctan2}\\left(p_x, p_z\\right)}{2\\pi}+0.5,\\\\ v&amp;=\\frac{\\arcsin\\left(\\dfrac{p_y}{|\\mathbf{p}|}\\right)}{\\pi}+0.5, \\end{align} \\] Mapeamento UV unwrap Em vez de usar as funções anteriores de mapeamento de textura, podemos definir diretamente quais são as coordenadas \\((u,v)\\) de cada vértice da malha geométrica. Isso pode ser feito através da inclusão de um atributo adicional de vértice, de forma semelhante como fizemos para a definição de cores nos vértices ou normais de vértices. Durante a rasterização, as coordenadas de textura definidas nos vértices são interpoladas para cada fragmento da primitiva. Assim, cada fragmento terá coordenadas de textura interpoladas, e a textura pode então ser amostrada no fragment shader. Para determinar as coordenadas \\((u,v)\\) de cada vértice de uma malha poligonal, técnicas de modelagem geométrica podem ser utilizadas para “desdobrar” a malha sobre o plano da textura, em um processo chamado de UV unwrap ou desdobramento UV. A figura 11.11 mostra um exemplo de objeto 3D renderizado com mapeamento UV unwrap. O objeto é uma lâmpada à óleo romana do acervo do Museu Britânico. O modelo original tem 500 mil triângulos e foi obtido através de varredura por um scanner 3D. Aqui, o modelo exibido tem apenas 10 mil triângulos para facilitar a visualização do mapeamento no sistema de coordenadas de textura. Observe, no mapa UV, como a malha é recortada em diferentes pedaços para ser desdobrada sem sobreposições sobre o plano. O mapeamento procura manter a proporção entre a área dos polígonos originais de modo que a densidade dos texels amostrados na superfície seja a mais uniforme possível. Figura 11.11: Mapeamento UV. Como referência, a figura 11.12 mostra o mapa de textura utilizado e o objeto sem texturização. Figura 11.12: Mapa de textura da lâmpada romana, e objeto sem textura. O desdobramento UV é a técnica mais utilizada de mapeamento de texturas em programas de modelagem e renderização, como o Blender. O formato OBJ suporta modelos com coordenadas de textura por vértice definidas através de desdobramento UV. "],["texwrapping.html", "11.2 Empacotamento", " 11.2 Empacotamento No OpenGL, o modo de empacotamento da textura (em inglês, texture wrapping) define o comportamento do amostrador de textura quando as coordenadas \\((u,v)\\) estão fora do intervalo \\([0, 1]\\). Há três comportamentos principais: GL_REPEAT: repete a textura fora do intervalo. Esse é o modo padrão de empacotamento. GL_MIRRORED_REPEAT: igual ao anterior, mas a textura é espelhada em \\(u\\) e/ou \\(v\\) quando a parte inteira da coordenada é um número ímpar. GL_CLAMP_TO_EDGE: Fixa as coordenadas no intervalo \\([0, 1]\\). O resultado é a repetição dos valores das primeiras e últimas linhas/colunas da textura. A figura 11.13 mostra o resultado dos diferentes modos de empacotamento no intervalo de \\((-1,-1)\\) a \\((2,2)\\) no espaço de textura. Figura 11.13: Modos de empacotamento do OpenGL. O modo de repetição (GL_REPEAT) é frequentemente utilizado para produzir padrões formados por texturas ininterruptas (seamless textures). Essas texturas, quando dispostas lado a lado ou como um ladrilho, formam um padrão contínuo. Um exemplo é mostrado na figura 11.14. Figura 11.14: Textura ininterrupta com empacotamento GL_REPEAT (adaptado do original). O modo de empacotamento é configurado com a função glTexParameteri. É possível configurar um comportamento diferente para a direção \\(u\\) (com GL_TEXTURE_WRAP_S) e direção \\(v\\) (com GL_TEXTURE_WRAP_T). Por exemplo, o código a seguir habilita o modo de repetição em \\(u\\) e o modo de repetição espelhada em \\(v\\): glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT); Em texturas 3D, é possível usar ainda a direção \\(w\\) (com GL_TEXTURE_WRAP_R). Outros modos de empacotamento estão disponíveis além dos modos GL_REPEAT, GL_MIRRORED_REPEAT e GL_CLAMP_TO_EDGE, mas não são suportados em todas as especificações do OpenGL. Por exemplo, o modo GL_CLAMP_TO_BORDER, que usa uma cor sólida para texels fora do intervalo \\([0,1]\\), não é suportado no OpenGL ES utilizado no WebGL. "],["texfiltering.html", "11.3 Filtragem", " 11.3 Filtragem Na amostragem de texturas, raramente temos um mapeamento \\(1:1\\) entre texels e pixels. Geralmente, cada pixel corresponde a vários texels, ou um mesmo texel pode ser mapeado a vários pixels. Tanto o problema de minificação (mais de um texel mapeado para um único pixel) quanto de magnificação (mais de um pixel mapeado para um mesmo texel) exigem o uso de filtros de interpolação para calcular a cor correspondente a uma posição \\((u,v)\\) no espaço da textura. No OpenGL, o funcionamento desses filtros pode ser configurado de forma independente usando os identificadores GL_TEXTURE_MAG_FILTER e GL_TEXTURE_MIN_FILTER com a função glTexParameteri. Magnificação Os filtros de magnificação (GL_TEXTURE_MAG_FILTER) são dois: Interpolação por vizinho mais próximo (GL_NEAREST): consiste em usar o valor do texel que está mais próximo da posição \\((u,v)\\) de amostragem, considerando a menor distância Manhattan entre os quatro texels mais próximos. Assim, os texels da textura aumentada têm um aspecto pixelado. Esse modo pode ser habilitado com glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); Interpolação bilinear (GL_LINEAR): consiste em realizar uma média entre os quatro texels mais próximos da posição \\((u, v)\\) de amostragem. Isso é feito calculando a interpolação linear entre dois pares de texels em uma direção (por exemplo, direção \\(u\\)), e calculando em seguida a interpolação linear dos dois valores resultantes na outra direção (por exemplo, direção \\(v\\)). Essa é a filtragem padrão do OpenGL. A interpolação bilinear é ativada com glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); A figura 11.15 mostra a comparação entre os dois filtros em um mesmo detalhe ampliado de textura. Figura 11.15: Exemplo de uso de filtros de magnificação do OpenGL. Minificação Os filtros de minificação do OpenGL (GL_TEXTURE_MIN_FILTER) também incluem os filtros de interpolação por vizinho mais próximo (GL_NEAREST) e interpolação bilinear (GL_LINEAR), e podem ser ativados respectivamente com glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); e glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); Entretanto, na minificação, é possível que mais do que quatro texels sejam mapeados para um mesmo pixel. Em tais casos, a filtragem bilinear usando somente os quatro vizinhos mais próximos não é suficiente, e erros de aliasing podem ser introduzidos. Uma forma eficiente de reduzir esse problema é através da técnica de mipmapping. Mipmapping Um mipmap é uma sequência ordenada de texturas repetidas, cada uma com metade da resolução da textura anterior. O nível base ou nível 0 do mipmap é a textura em sua resolução original. A textura do nível seguinte contém metade da resolução da textura do nível anterior. No último nível do mipmap, a textura tem tamanho \\(1 \\times 1\\). A figura 11.16 mostra todos os níveis de um mipmap para uma textura de resolução \\(256 \\times 256\\). Figura 11.16: Níveis de mipmap. Se a textura é quadrada e a resolução é uma potência de dois, um texel de um nível do mipmap é definido de tal forma que seu valor é exatamente a média entre quatro texels do nível anterior. Isso pode ser visto na figura 11.17, que mostra o detalhe ampliado dos três últimos níveis do mipmap da figura 11.16. Observe, no nível 8, que a cor do único texel resultante é cinza. Essa cor cinza é a média de todos os texels do nível anterior (nível 7), que é o mesmo que a média de todos os texels da textura. De forma semelhante, no nível 7, o texel mais escuro (canto inferior esquerdo) é a média dos texels de \\((0,0)\\) até \\((0.5, 0.5)\\) dos níveis anteriores. Figura 11.17: Detalhe ampliado dos três últimos níveis de um mipmap. A figura 11.18 mostra uma comparação da qualidade de renderização de um padrão de xadrez sobre um plano, sem e com mipmapping. A renderização sem mapping introduz artefatos de aliasing espacial resultantes da subamostragem. Figura 11.18: Comparação de renderização sem mipmapping (esquerda) e com mipmapping (direita) (fonte). No OpenGL, um mipmap pode ser gerado facilmente com a função glGenerateMipmap. Quando a função é chamada, o mipmap é gerado para a textura atualmente ligada com glBindTexture. Por exemplo, glBindTexture(GL_TEXTURE_2D, textureID); glGenerateMipmap(GL_TEXTURE_2D); gera o mipmap para a textura com identificador textureID. Mipmapping é a técnica de filtrar texels usando mipmaps. Quando uma textura com mipmap é amostrada, o amostrador primeiro determina qual nível do mipmap será utilizado. Isso é calculado com base na estimativa do número de texels mapeados para o pixel. Por exemplo, se a área do texel projetado no espaço da janela é tal que todos os texels da textura cabem em um único pixel, então a textura amostrada é a textura do último nível (textura \\(1 \\times 1\\)), pois o texel dessa textura contém a média de todos os texels. No OpenGL, há diferentes modos de filtragem usando mipmapping (válido apenas para GL_TEXTURE_MIN_FILTER): GL_NEAREST_MIPMAP_NEAREST: escolhe o nível de mipmap que mais se aproxima do tamanho do pixel que está sendo texturizado, e então amostra tal nível usando a interpolação por vizinho mais próximo. GL_LINEAR_MIPMAP_NEAREST: escolhe o nível de mipmap que mais se aproxima do tamanho do pixel que está sendo texturizado, e então amostra tal nível usando a interpolação bilinear (média dos quatro texels mais próximos). GL_NEAREST_MIPMAP_LINEAR: escolhe os dois níveis de mipmap que mais se aproximam do tamanho do pixel que está sendo texturizado, e então amostra os dois níveis usando a interpolação por vizinho mais próximo. O valor final é então calculado como a média entre os dois valores amostrados, ponderada de acordo com a proximidade dos níveis de mipmap ao tamanho do pixel. Esse é o modo padrão de filtro de minificação. GL_LINEAR_MIPMAP_LINEAR: escolhe os dois níveis de mipmap que mais se aproximam do tamanho do pixel que está sendo texturizado, e então amostra os dois níveis usando interpolação bilinear. O valor final é então calculado como a média entre os dois valores amostrados, ponderada de acordo com a proximidade dos níveis de mipmap ao tamanho do pixel. O modo GL_LINEAR_MIPMAP_LINEAR também é chamado de interpolação trilinear, pois faz uma interpolação linear sobre dois valores obtidos com interpolação bilinear. Esse é o modo de filtragem que produz resultados com menos artefatos de aliasing, mas também é o mais custoso. "],["viewer4.html", "11.4 Texturização na prática", " 11.4 Texturização na prática Nesta seção, daremos continuidade ao projeto do visualizador de modelos 3D apresentado na seção 10.6. Esta será a versão 4 do visualizador (viewer4) e terá um shader que usa uma textura para modificar as propriedades de reflexão difusa (\\(\\kappa_d\\)) e ambiente (\\(\\kappa_a\\)) do material utilizado no modelo de reflexão de Blinn–Phong. Se o objeto lido do arquivo OBJ já vier com coordenadas de textura definidas em seus vértices (mapeamento UV unwrap), o visualizador usará essas coordenadas para amostrar a textura. Entretanto, também poderemos selecionar, através da interface da ImGui, um mapeamento pré-definido: triplanar, cilíndrico ou esférico. Nesta nova versão, o botão “Load 3D Model” será transformado em um item do menu “File”. Há também uma opção de menu para carregar uma textura como um arquivo de imagem no formato PNG ou JPEG. O resultado ficará como a seguir: Como o código dessa versão contém apenas mudanças incrementais em relação ao anterior, nosso foco será apenas nessas mudanças. Baixe o código completo deste link. Carregando texturas Para carregar uma textura no OpenGL, primeiro devemos chamar a função glGenTextures que cria um ou mais recursos de textura. Por exemplo, para criar apenas uma textura, podemos fazer glGenTextures(1, &amp;textureID); onde textureID é uma variável do tipo GLuint que será preenchida com o identificador do recurso de textura criado pelo OpenGL. Em seguida, ligamos o recurso de textura a um “alvo de textura”, que é GL_TEXTURE_2D para texturas 2D: glBindTexture(GL_TEXTURE_2D, textureID); Neste momento, a textura ainda está vazia. Para definir seu conteúdo, devemos ter um mapa de bits. Podemos carregar o conteúdo do mapa de bits através da função glTexImage2D. Por exemplo, considere o código a seguir: glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, 800, 600, 0, GL_RGBA, GL_UNSIGNED_BYTE, pixels); glTexImage2D copia o mapa de bits contido no ponteiro pixels, supondo que o mapa é um arranjo de \\(800 \\times 600\\) pixels. A função considera que cada pixel é uma tupla de valores RGBA (GL_RGBA), e que cada componente de cor é um byte sem sinal (GL_UNSIGNED_BYTE). Na ABCg podemos usar a função auxiliar abcg::loadOpenGLTexture. Essa função recebe uma estrutura abcg::OpenGLTextureCreateInfo com informações sobre a criação da textura, tal como o nome de um arquivo de imagem. O valor de retorno é o identificar da textura criada. Internamente, a função usa funções da SDL para carregar o mapa de bits, e em seguida chama as funções do OpenGL para criar o recurso de textura. Assim, para criar uma textura a partir de um arquivo imagem.png, podemos fazer simplesmente: textureID = abcg::loadOpenGLTexture({.path = &quot;imagem.png&quot;}); Por padrão, abcg::loadOpenGLTexture cria também o mipmap da textura e usa o filtro de minificação GL_LINEAR_MIPMAP_LINEAR. Se quisermos que o mipmap não seja gerado, basta mudar o valor de OpenGLTextureCreateInfo::generateMipmaps para false: textureID = abcg::opengl::loadTexture({.path = &quot;imagem.png&quot;, .generateMipmaps = false}); Para destruir a textura e liberar seus recursos, devemos chamar manualmente glDeleteTextures. Por exemplo, o seguinte código libera a textura textureID criada com glGenTextures ou abcg::loadOpenGLTexture. glDeleteTextures(1, &amp;textureID); Nessa nova versão do visualizador, a classe Model implementa a função membro Model::loadDiffuseTexture, que carrega um arquivo de imagem e gera um identificador de recurso de textura difusa na variável m_diffuseTexture. A função é definida como a seguir (em model.cpp): void Model::loadDiffuseTexture(std::string_view path) { if (!std::filesystem::exists(path)) return; abcg::glDeleteTextures(1, &amp;m_diffuseTexture); m_diffuseTexture = abcg::loadOpenGLTexture({.path = path}); } A função recebe em path o caminho contendo o nome do arquivo de imagem PNG ou JPEG. Se o arquivo não existir, a função simplesmente retorna (linha 72). Caso contrário, o recurso de textura anterior é liberado, e abcg::loadOpenGLTexture é chamada para criar a nova textura. Carregando modelos com textura Um arquivo OBJ pode vir acompanhado de um arquivo .mtl opcional que contém a descrição das propriedades dos materiais de cada objeto1. Por exemplo, o arquivo roman_lamp.obj (lâmpada romana da figura 11.11) vem acompanhado do arquivo roman_lamp.mtl que tem o seguinte conteúdo: newmtl roman_lamp Ns 25.0000 Ni 1.5000 Tr 0.0000 Tf 1.0000 1.0000 1.0000 illum 2 Ka 0.2000 0.2000 0.2000 Kd 1.0000 1.0000 1.0000 Ks 0.6000 0.6000 0.6000 Ke 0.0000 0.0000 0.0000 map_Ka maps/roman_lamp_diffuse.jpg map_Kd maps/roman_lamp_diffuse.jpg map_bump maps/roman_lamp_normal.jpg bump maps/roman_lamp_normal.jpg Entre outras coisas, o arquivo contém o valor do expoente de brilho especular (Ns) e as propriedades de reflexão ambiente (Ka), difusa (Kd) e especular (Ks). Além disso, o arquivo contém o nome do mapa de textura que deve ser utilizado para modificar a reflexão ambiente (map_Ka) e reflexão difusa (map_Kd). Há outras propriedades, mas elas não serão utilizadas no momento. Nossa implementação de Model::loadObj, que utiliza funções da TinyObjLoader, carrega automaticamente a textura difusa, se ela existir. A definição completa dessa versão atualizada de Model::loadObj é mostrada seguir (arquivo model.cpp). void Model::loadObj(std::string_view path, bool standardize) { auto const basePath{std::filesystem::path{path}.parent_path().string() + &quot;/&quot;}; tinyobj::ObjReaderConfig readerConfig; readerConfig.mtl_search_path = basePath; // Path to material files tinyobj::ObjReader reader; if (!reader.ParseFromFile(path.data(), readerConfig)) { if (!reader.Error().empty()) { throw abcg::RuntimeError( fmt::format(&quot;Failed to load model {} ({})&quot;, path, reader.Error())); } throw abcg::RuntimeError(fmt::format(&quot;Failed to load model {}&quot;, path)); } if (!reader.Warning().empty()) { fmt::print(&quot;Warning: {}\\n&quot;, reader.Warning()); } auto const &amp;attrib{reader.GetAttrib()}; auto const &amp;shapes{reader.GetShapes()}; auto const &amp;materials{reader.GetMaterials()}; m_vertices.clear(); m_indices.clear(); m_hasNormals = false; m_hasTexCoords = false; // A key:value map with key=Vertex and value=index std::unordered_map&lt;Vertex, GLuint&gt; hash{}; // Loop over shapes for (auto const &amp;shape : shapes) { // Loop over indices for (auto const offset : iter::range(shape.mesh.indices.size())) { // Access to vertex auto const index{shape.mesh.indices.at(offset)}; // Position auto const startIndex{3 * index.vertex_index}; glm::vec3 position{attrib.vertices.at(startIndex + 0), attrib.vertices.at(startIndex + 1), attrib.vertices.at(startIndex + 2)}; // Normal glm::vec3 normal{}; if (index.normal_index &gt;= 0) { m_hasNormals = true; auto const normalStartIndex{3 * index.normal_index}; normal = {attrib.normals.at(normalStartIndex + 0), attrib.normals.at(normalStartIndex + 1), attrib.normals.at(normalStartIndex + 2)}; } // Texture coordinates glm::vec2 texCoord{}; if (index.texcoord_index &gt;= 0) { m_hasTexCoords = true; auto const texCoordsStartIndex{2 * index.texcoord_index}; texCoord = {attrib.texcoords.at(texCoordsStartIndex + 0), attrib.texcoords.at(texCoordsStartIndex + 1)}; } Vertex const vertex{ .position = position, .normal = normal, .texCoord = texCoord}; // If hash doesn&#39;t contain this vertex if (!hash.contains(vertex)) { // Add this index (size of m_vertices) hash[vertex] = m_vertices.size(); // Add this vertex m_vertices.push_back(vertex); } m_indices.push_back(hash[vertex]); } } // Use properties of first material, if available if (!materials.empty()) { auto const &amp;mat{materials.at(0)}; // First material m_Ka = {mat.ambient[0], mat.ambient[1], mat.ambient[2], 1}; m_Kd = {mat.diffuse[0], mat.diffuse[1], mat.diffuse[2], 1}; m_Ks = {mat.specular[0], mat.specular[1], mat.specular[2], 1}; m_shininess = mat.shininess; if (!mat.diffuse_texname.empty()) loadDiffuseTexture(basePath + mat.diffuse_texname); } else { // Default values m_Ka = {0.1f, 0.1f, 0.1f, 1.0f}; m_Kd = {0.7f, 0.7f, 0.7f, 1.0f}; m_Ks = {1.0f, 1.0f, 1.0f, 1.0f}; m_shininess = 25.0f; } if (standardize) { Model::standardize(); } if (!m_hasNormals) { computeNormals(); } createBuffers(); } Note que, logo no início da função, definimos um objeto readerConfig (linha 81) que é utilizado como argumento de ObjReader::ParseFromFile da TinyObjLoader (linha 86) para informar o diretório onde estão os arquivos de materiais. Por padrão, esse caminho é o mesmo diretório onde está o arquivo OBJ: void Model::loadObj(std::string_view path, bool standardize) { auto const basePath{std::filesystem::path{path}.parent_path().string() + &quot;/&quot;}; tinyobj::ObjReaderConfig readerConfig; readerConfig.mtl_search_path = basePath; // Path to material files tinyobj::ObjReader reader; if (!reader.ParseFromFile(path.data(), readerConfig)) { if (!reader.Error().empty()) { throw abcg::RuntimeError( fmt::format(&quot;Failed to load model {} ({})&quot;, path, reader.Error())); } throw abcg::RuntimeError(fmt::format(&quot;Failed to load model {}&quot;, path)); } if (!reader.Warning().empty()) { fmt::print(&quot;Warning: {}\\n&quot;, reader.Warning()); } Nas linhas 158 a 174, as propriedades do primeiro material são utilizadas. Se não houver nenhum material, valores padrão são utilizados: // Use properties of first material, if available if (!materials.empty()) { auto const &amp;mat{materials.at(0)}; // First material m_Ka = {mat.ambient[0], mat.ambient[1], mat.ambient[2], 1}; m_Kd = {mat.diffuse[0], mat.diffuse[1], mat.diffuse[2], 1}; m_Ks = {mat.specular[0], mat.specular[1], mat.specular[2], 1}; m_shininess = mat.shininess; if (!mat.diffuse_texname.empty()) loadDiffuseTexture(basePath + mat.diffuse_texname); } else { // Default values m_Ka = {0.1f, 0.1f, 0.1f, 1.0f}; m_Kd = {0.7f, 0.7f, 0.7f, 1.0f}; m_Ks = {1.0f, 1.0f, 1.0f, 1.0f}; m_shininess = 25.0f; } Durante a leitura dos atributos dos vértices, Model::loadObj também verifica se a malha contém coordenadas de textura. Isso é feito nas linhas 134 a 141: // Texture coordinates glm::vec2 texCoord{}; if (index.texcoord_index &gt;= 0) { m_hasTexCoords = true; auto const texCoordsStartIndex{2 * index.texcoord_index}; texCoord = {attrib.texcoords.at(texCoordsStartIndex + 0), attrib.texcoords.at(texCoordsStartIndex + 1)}; } Se o vértice contém coordenadas de textura (linha 136), o flag m_hasTexCoords é definido como true e as coordenadas são carregadas em texCoord. Se o arquivo OBJ não tiver coordenadas de textura, texCoord será (0, 0) para todos os vértices. A estrutura Vertex é criada com o novo atributo de coordenadas de textura: Vertex const vertex{ .position = position, .normal = normal, .texCoord = texCoord}; texCoord é um novo atributo de Vertex (um glm::vec2), criado de forma semelhante ao modo como criamos o atributo normal no projeto viewer2 (seção 10.5), isto é, usamos o atributo como chave de hash e carregamos seus dados no formato de um VBO de dados intercalados. Renderizando Em Model::render (chamado em Window::onPaint), incluímos a ativação da textura no pipeline. A definição completa ficará como a seguir: void Model::render(int numTriangles) const { abcg::glBindVertexArray(m_VAO); abcg::glActiveTexture(GL_TEXTURE0); abcg::glBindTexture(GL_TEXTURE_2D, m_diffuseTexture); // Set minification and magnification parameters abcg::glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); abcg::glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); // Set texture wrapping parameters abcg::glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); abcg::glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); auto const numIndices{(numTriangles &lt; 0) ? m_indices.size() : numTriangles * 3}; abcg::glDrawElements(GL_TRIANGLES, numIndices, GL_UNSIGNED_INT, nullptr); abcg::glBindVertexArray(0); } Na linha 190, a função glActiveTexture é chamada para ativar a primeira “unidade de textura” (GL_TEXTURE0). O número de unidades de textura ativas corresponde ao número de texturas diferentes que podem ser utilizadas ao mesmo tempo em um programa de shader. Para cada estágio de shader (por exemplo, para o vertex shader, ou para o fragment shader) é possível acessar pelo menos 16 unidades de textura ao mesmo tempo. Esse número pode ser maior dependendo da implementação do driver. Se considerarmos todas os estágios de shaders disponíveis, então podemos ativar pelo menos 32 texturas ao mesmo tempo no OpenGL ES (16 para o vertex shader, mais 16 para o fragment shader), e 80 no OpenGL para desktop (16 para cada um dos 5 estágios de shaders). Como queremos manter as coisas simples, nosso visualizador por enquanto só utilizará uma unidade de textura. Nas próximas versões veremos como usar mais unidades. Após a ativação da unidade de textura, a função glBindTexture é chamada para ligar o identificar de textura à unidade recém ativada. Nas linha 193 a 199, a função glTexParameteri é chamada para configurar os filtros de textura e modos de empacotamento. Os valores aqui utilizados são os valores padrão do OpenGL. Isso é tudo para configurar a texturização. O restante agora é feito nos shaders. O projeto viewer4 define dois novos shaders com suporte a texturas: texture.vert e texture.frag. Esses shaders são bem similares aos shaders do modelo de Blinn–Phong. Observação Para o conteúdo de assets ficar mais organizado, a partir desta versão do visualizador, as texturas ficarão armazenadas em assets/maps, e os shaders ficarão armazenados em assets/shaders. Os arquivos .obj continuam na pasta assets, agora junto também com os arquivos .mtl. texture.vert O código completo do shader é mostrado a seguir: #version 300 es layout(location = 0) in vec3 inPosition; layout(location = 1) in vec3 inNormal; layout(location = 2) in vec2 inTexCoord; uniform mat4 modelMatrix; uniform mat4 viewMatrix; uniform mat4 projMatrix; uniform mat3 normalMatrix; uniform vec4 lightDirWorldSpace; out vec3 fragV; out vec3 fragL; out vec3 fragN; out vec2 fragTexCoord; out vec3 fragPObj; out vec3 fragNObj; void main() { vec3 P = (viewMatrix * modelMatrix * vec4(inPosition, 1.0)).xyz; vec3 N = normalMatrix * inNormal; vec3 L = -(viewMatrix * lightDirWorldSpace).xyz; fragL = L; fragV = -P; fragN = N; fragTexCoord = inTexCoord; fragPObj = inPosition; fragNObj = inNormal; gl_Position = projMatrix * vec4(P, 1.0); } Esse código contém algumas poucas modificações em relação ao conteúdo de blinnphong.vert. Observe como agora temos o atributo de entrada inTexCoord (linha 5) contendo as coordenadas de textura lidas do arquivo OBJ. O vertex shader não faz nenhum processamento com as coordenadas de textura e simplesmente passa-as adiante para o fragment shader através do atributo de saída fragTexCoord (linha 17). O vertex shader também possui dois outros atributos adicionais de saída: fragPObj (linha 18) é a posição do vértice no espaço do objeto (isto é, uma cópia de inPosition); fragNObj (linha 19) é o vetor normal no espaço do objeto (isto é, uma cópia de inNormal). Esses atributos são utilizados para calcular, no fragment shader, as coordenadas de textura do mapeamento triplanar, cilíndrico ou esférico (o vetor normal só é utilizado no mapeamento triplanar). Se o mapeamento utilizado é aquele fornecido pelo arquivo OBJ, isto é, o mapeamento determinado pelas coordenada de textura de inTexCoord, então os atributos fragPObj e fragNObj não são utilizados. texture.frag O código completo do shader é mostrado a seguir: #version 300 es precision mediump float; in vec3 fragN; in vec3 fragL; in vec3 fragV; in vec2 fragTexCoord; in vec3 fragPObj; in vec3 fragNObj; // Light properties uniform vec4 Ia, Id, Is; // Material properties uniform vec4 Ka, Kd, Ks; uniform float shininess; // Diffuse texture sampler uniform sampler2D diffuseTex; // Mapping mode // 0: triplanar; 1: cylindrical; 2: spherical; 3: from mesh uniform int mappingMode; out vec4 outColor; // Blinn-Phong reflection model vec4 BlinnPhong(vec3 N, vec3 L, vec3 V, vec2 texCoord) { N = normalize(N); L = normalize(L); // Compute lambertian term float lambertian = max(dot(N, L), 0.0); // Compute specular term float specular = 0.0; if (lambertian &gt; 0.0) { V = normalize(V); vec3 H = normalize(L + V); float angle = max(dot(H, N), 0.0); specular = pow(angle, shininess); } vec4 map_Kd = texture(diffuseTex, texCoord); vec4 map_Ka = map_Kd; vec4 diffuseColor = map_Kd * Kd * Id * lambertian; vec4 specularColor = Ks * Is * specular; vec4 ambientColor = map_Ka * Ka * Ia; return ambientColor + diffuseColor + specularColor; } // Planar mapping vec2 PlanarMappingX(vec3 P) { return vec2(1.0 - P.z, P.y); } vec2 PlanarMappingY(vec3 P) { return vec2(P.x, 1.0 - P.z); } vec2 PlanarMappingZ(vec3 P) { return P.xy; } #define PI 3.14159265358979323846 // Cylindrical mapping vec2 CylindricalMapping(vec3 P) { float longitude = atan(P.x, P.z); float height = P.y; float u = longitude / (2.0 * PI) + 0.5; // From [-pi, pi] to [0, 1] float v = height - 0.5; // Base at y = -0.5 return vec2(u, v); } // Spherical mapping vec2 SphericalMapping(vec3 P) { float longitude = atan(P.x, P.z); float latitude = asin(P.y / length(P)); float u = longitude / (2.0 * PI) + 0.5; // From [-pi, pi] to [0, 1] float v = latitude / PI + 0.5; // From [-pi/2, pi/2] to [0, 1] return vec2(u, v); } void main() { vec4 color; if (mappingMode == 0) { // Triplanar mapping // Sample with x planar mapping vec2 texCoord1 = PlanarMappingX(fragPObj); vec4 color1 = BlinnPhong(fragN, fragL, fragV, texCoord1); // Sample with y planar mapping vec2 texCoord2 = PlanarMappingY(fragPObj); vec4 color2 = BlinnPhong(fragN, fragL, fragV, texCoord2); // Sample with z planar mapping vec2 texCoord3 = PlanarMappingZ(fragPObj); vec4 color3 = BlinnPhong(fragN, fragL, fragV, texCoord3); // Compute average based on normal vec3 weight = abs(normalize(fragNObj)); color = color1 * weight.x + color2 * weight.y + color3 * weight.z; } else { vec2 texCoord; if (mappingMode == 1) { // Cylindrical mapping texCoord = CylindricalMapping(fragPObj); } else if (mappingMode == 2) { // Spherical mapping texCoord = SphericalMapping(fragPObj); } else if (mappingMode == 3) { // From mesh texCoord = fragTexCoord; } color = BlinnPhong(fragN, fragL, fragV, texCoord); } if (gl_FrontFacing) { outColor = color; } else { float i = (color.r + color.g + color.b) / 3.0; outColor = vec4(i, 0, 0, 1.0); } } A primeira mudança em relação ao shader blinnphong.frag é o número de atributos de entrada, que agora inclui os atributos fragTexCoord, fragPObj e fragNObj da saída do vertex shader: in vec3 fragN; in vec3 fragL; in vec3 fragV; in vec2 fragTexCoord; in vec3 fragPObj; in vec3 fragNObj; Há também duas novas variáveis uniformes: // Diffuse texture sampler uniform sampler2D diffuseTex; // Mapping mode // 0: triplanar; 1: cylindrical; 2: spherical; 3: from mesh uniform int mappingMode; diffuseTex é um amostrador de textura 2D (sampler2D) que acessa a primeira unidade de textura (GL_TEXTURE0) ativada com glActiveTexture em Model::render. É através desse amostrador que conseguiremos acessar os texels da textura difusa. mappingMode é um inteiro que identifica o modo de mapeamento escolhido pelo usuário. Esse valor é determinado pelo índice da caixa de combinação “UV mapping” da ImGui. O padrão é 3 para arquivos OBJ que possuem coordenadas de textura, e 0 quando as coordenadas de textura não foram encontradas. Importante O pipeline associa diffuseTex à unidade de textura GL_TEXTURE0 pois o valor dessa variável uniforme é definido como 0 no código em C++. Isso é feito na linha 106 de Window::onPaint junto com a definição das outras variáveis uniformes: auto const diffuseTexLoc{abcg::glGetUniformLocation(program, &quot;diffuseTex&quot;)}; auto const mappingModeLoc{abcg::glGetUniformLocation(program, &quot;mappingMode&quot;)}; // Set uniform variables that have the same value for every model abcg::glUniformMatrix4fv(viewMatrixLoc, 1, GL_FALSE, &amp;m_viewMatrix[0][0]); abcg::glUniformMatrix4fv(projMatrixLoc, 1, GL_FALSE, &amp;m_projMatrix[0][0]); abcg::glUniform1i(diffuseTexLoc, 0); abcg::glUniform1i(mappingModeLoc, m_mappingMode); A definição da função BlinnPhong é ligeiramente diferente daquela do shader blinnphong.frag: // Blinn-Phong reflection model vec4 BlinnPhong(vec3 N, vec3 L, vec3 V, vec2 texCoord) { N = normalize(N); L = normalize(L); // Compute lambertian term float lambertian = max(dot(N, L), 0.0); // Compute specular term float specular = 0.0; if (lambertian &gt; 0.0) { V = normalize(V); vec3 H = normalize(L + V); float angle = max(dot(H, N), 0.0); specular = pow(angle, shininess); } vec4 map_Kd = texture(diffuseTex, texCoord); vec4 map_Ka = map_Kd; vec4 diffuseColor = map_Kd * Kd * Id * lambertian; vec4 specularColor = Ks * Is * specular; vec4 ambientColor = map_Ka * Ka * Ia; return ambientColor + diffuseColor + specularColor; } Agora, a função tem o parâmetro adicional de coordenadas de textura texCoord (linha 29). Até a linha 43, o código é igual ao anterior. A linha 45 contém o código utilizado para amostrar a textura difusa. A função texture recebe como argumentos o amostrador de textura (diffuseTex) e as coordenadas de textura (texCoord). O resultado é a cor RGBA amostrada na posição dada, usando o modo de filtragem e modo de empacotamento definidos pelo código C++ antes da renderização. Como estamos amostrando uma textura difusa, a cor da textura (map_Kd) é multiplicada por Kd * Id * lambertian para compor a componente difusa final (linha 48). Também criamos uma cor ambiente map_Ka (linha 46) que multiplica as componentes de reflexão ambiente (linha 50). Nesse caso, consideramos que map_Ka é igual a map_Kd, pois geralmente é esse o caso (a textura difusa é também a textura ambiente). Entretanto, é possível que um material defina uma textura diferente para a componente ambiente. Nesse caso teríamos de mudar o shader para incluir um outro amostrador específico para map_Ka. Além da função BlinnPhong, o shader também define as funções de geração de coordenadas de textura usando mapeamento planar (PlanarMappingX, PlanarMappingY, PlanarMappingZ), cilíndrico (CylindricalMapping) e esférico (SphericalMapping): // Planar mapping vec2 PlanarMappingX(vec3 P) { return vec2(1.0 - P.z, P.y); } vec2 PlanarMappingY(vec3 P) { return vec2(P.x, 1.0 - P.z); } vec2 PlanarMappingZ(vec3 P) { return P.xy; } #define PI 3.14159265358979323846 // Cylindrical mapping vec2 CylindricalMapping(vec3 P) { float longitude = atan(P.x, P.z); float height = P.y; float u = longitude / (2.0 * PI) + 0.5; // From [-pi, pi] to [0, 1] float v = height - 0.5; // Base at y = -0.5 return vec2(u, v); } // Spherical mapping vec2 SphericalMapping(vec3 P) { float longitude = atan(P.x, P.z); float latitude = asin(P.y / length(P)); float u = longitude / (2.0 * PI) + 0.5; // From [-pi, pi] to [0, 1] float v = latitude / PI + 0.5; // From [-pi/2, pi/2] to [0, 1] return vec2(u, v); } Todas as funções recebem como parâmetro a posição do ponto (P) e retornam as coordenadas de textura correspondentes ao mapeamento. O código reproduz as equações descritas na seção 11.1. A única exceção é o cálculo da componente \\(v\\) do mapeamento cilíndrico (linha 68), que aqui é deslocada para fazer com que o cilindro tenha base em \\(-0.5\\) em vez de \\(0\\). Assim, a textura fica centralizada verticalmente em objetos de raio unitário centralizados na origem, que é o nosso caso pois usamos a função Model::standardize após a leitura do arquivo OBJ. As funções de geração de coordenadas de textura são chamadas em main de acordo com o valor de mappingMode: void main() { vec4 color; if (mappingMode == 0) { // Triplanar mapping // Sample with x planar mapping vec2 texCoord1 = PlanarMappingX(fragPObj); vec4 color1 = BlinnPhong(fragN, fragL, fragV, texCoord1); // Sample with y planar mapping vec2 texCoord2 = PlanarMappingY(fragPObj); vec4 color2 = BlinnPhong(fragN, fragL, fragV, texCoord2); // Sample with z planar mapping vec2 texCoord3 = PlanarMappingZ(fragPObj); vec4 color3 = BlinnPhong(fragN, fragL, fragV, texCoord3); // Compute average based on normal vec3 weight = abs(normalize(fragNObj)); color = color1 * weight.x + color2 * weight.y + color3 * weight.z; } else { vec2 texCoord; if (mappingMode == 1) { // Cylindrical mapping texCoord = CylindricalMapping(fragPObj); } else if (mappingMode == 2) { // Spherical mapping texCoord = SphericalMapping(fragPObj); } else if (mappingMode == 3) { // From mesh texCoord = fragTexCoord; } color = BlinnPhong(fragN, fragL, fragV, texCoord); } if (gl_FrontFacing) { outColor = color; } else { float i = (color.r + color.g + color.b) / 3.0; outColor = vec4(i, 0, 0, 1.0); } } Observe, no mapeamento triplanar (linhas 88–104), como a textura é amostrada três vezes (linhas 90–100) e as cores amostrada são combinadas em uma média ponderada pelo valor absoluto das componentes do vetor normal (linhas 103–104). Observação Observe que, no mapeamento triplanar, não seria necessário chamar BlinnPhong três vezes. Afinal, a iluminação sem a textura é a mesma nas três chamadas. O código ficaria mais eficiente se BlinnPhong retornasse uma estrutura contendo as componentes ambiente, difusa e especular separadas. Poderíamos então criar uma outra função só para fazer a amostragem da textura difusa e compor a cor final. Se mappingMode é 3, então nenhuma função de mapeamento é chamada e as coordenadas de textura utilizadas em BlinnPhong são aquelas contidas em fragTexCoord, pois essas são as coordenadas de textura interpoladas a partir das coordenadas definidas nos vértices. Isso resume as modificações necessárias para habilitar a texturização. O restante do código contém modificações complementares relacionadas a conceitos que já foram abordados em projetos anteriores, como a mudança da interface da ImGui e a determinação de um ângulo e eixo de rotação inicial para o trackball virtual. Nosso visualizador suporta apenas um objeto por arquivo OBJ e, portanto, suporta apenas um material. Por isso, todos os arquivos OBJ que utilizaremos devem ter apenas um objeto e um material.↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
